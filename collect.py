from collections import Counter
import re

filename = './countData.txt'
datalist = []
exclude_words=['', 'three', 'party', 'section', 'neither', 'tional', 'every', 'found', 'form', 'airlines', 'f', 'relations', 'civil', 'united', 'too.', 'used', 'it,', 'french', 'national', 'far', 'across', 'mid', 't', 'who', 'those', 'law', 'per', 'home', 'best', 're', 'become', 'do', 'bank', '%', 'before', 'no', 'technology', 'own', 'think', 'himself', 'among', 'saying', 'using', 'russia', 'down', 'flight', 'look', 'ftc', 'german', 'cambridge', 'experience', 'industry', 'likely', 'par', 'south', 'few', 'er', 'trump’s', 'political', 'right', 'not', 'rise', 'open', 'had', 'support', 'venues', 'low', 'thus', 'left', 'make', 'our', 'film', 'your', 'companies', 'single', 'income', 'share', 'north', 'order', 'full', 'another', 'countries', 'while', 'each', 'yokai', 'its', 'business', 'march', 'other', 'inside', 'turned', 'tive', 'there', 'real', 'un', 'paying', 'oil', 'poor', 'being', 'presi', 'biggest', 'british', 'con', 'early', 'such', 'same', 'back', 'prime', 'economist', 'self', 'regulation', 'r', 'privacy', 'as', 'many', 'politics', 'shakur', 'o', 'years.', 'mother', 'limited', 'up', 'so', 'rich', 'l', 'past', 'at', 'passengers', 'despite', 'govern', 'payments', 'trump', 'still', 'european', 'university', 'central', 'la', 'late', 'why', 'system', 'hip-hop', 'gov', 'held', 'team', 'group', 'culture', 'ex', 'give', '40', 'country', 'two', 'men', 'worth', 'microbots', 'rather', 'enough', 'through', 'because', 'though', 'world’s', 'murder', 'especially', 'more', 'went', 'under', 'than', 'children', 'ica', 'american', 'chairman', '50', 'foreign', 'president', 'classrooms', 'that', 'already', 'ﬁnancial', 'incident', 'often', 'of', 'long', 'means', 'given', 'growth', 'capital', 'huge', 'just', 'well', 'zuckerberg', 'would', 'hiro', 'some', 'high', 'nov', 'return', 'their', 'war', 'ap', 'an', 'made', 'work', 'disaster', 'very', 'dr', 'apps', 'genre', 'both', 'little', 'food', 'incident,', 'fransokyo', 'investigation', 'run', 'been', 'people', 'also', 'seen', 'get', '20', 'centre', 'part', 'school', 'chinese', 'put', 'it', 'ability', 'them', 'including', 'trade', 'states', 'cause', 'hero', 'large', 'fame', 'western', 'but', 'former', 'ads', 'ms', 'year.', 'west', 'london', 'p', 'seemed', 'use', 'tion', 'top', 'time', 'airlines,', 'tion,', 'online', 'set', '10', 'case', 'month', 'around', 'see', 'firm', 'how', 'limit', 'platforms', 'be', 'east', 'short', 'four', 'week', 'm', 'between', 'line', 'nuclear', 'details', 'd', '7', 'says', 'is', 'prices', 'should', 'power', 'government', 'care', 'c', 'survey', 'al', 'process', 'next', 'san', 'term', '2016', 'nor', 'go', 'too', 'data', 'music,', 'social', 'y', 'members', 'hard', 'airline', 'followed', 'over', 'interest', 'anti', 'international', 'on', '30', 'flights', 'things', 'ad', 'g', 'company', 'history', 'wants', 'did', 'music', 'ac', 'say', 'change', 'cannot', 'to', 'has', 'last', 'br', 'day', 'discussing', 'users', 'small', 'higher', 'ameri', 'yet', 'federal', 'always', 'rock', 'china', 'pay', 'groups', 'eu', 'after', 'most', 'man', 'longer', 'for', 'based', 'by', 'general', 'avoid', 'in', 'however,', '|', 'level', 'took', 'young', 'japan', 'ﬁrms', 'new', 'state', 'six', 'passenger', 'way', 'russian', 'that,', 'better', 'year,', 'once', 'or', 'point', 'leaders', 'old', 'investment', '12', 'lowest', 'main', 'page', 'china’s', 'know', 'future', 'ed', 'america', 'makes', 'place', 'house', 'move', 'similar', 'was', 'the', '2017', 'hiro,', 'menu', 'it.', 'co', 'e', 'may', 'politicians', 'special', 'tax', 'cost', 'europe', 'money', 'markets', 'need', 'voters', 'chip', 'white', 'never', 'turn', 'middle', 'independent', 'battle', 'if', 'they', 'media', 'boss', 'rate', 'owned', 'scandal', '“the', 'human', 'car', 'less', 'land', 'india', 'korea', 'out', 'against', 'growing', 'making', 'could', 'continue', 'able', '15', 'during', 'almost', 'seem', 'police', 'changes', 'promised', 'this', 'labour', 's', 'does', 'deal', 'ﬁve', 'pakistan', 'public', 'non', 'euro', 'price', 'switch', '1', 'him', 'about', 'led', 'current', 'are', 'one', 'years', 'economy', 'attention', 'hearing', 'with', 'ten', 'we', 'without', 'age', 'side', 'gdp', 'he', 'his', 'others', 'economic', 'pre', 'must', 'number', 'into', 'baymax,', 'tech', 'coun', 'ﬁnd', 'whose', 'lead', 'said', 'security', 'chief', 'tadashi', 'i', 'artists', 'sion', 'push', 'end', 'facebook', 'then', 'idea', 'pain', 'all', 'de', 'cut', 'vote', 'oﬀ', 'additional', 'n', 'want', 'rates', 'restore', 'military', 'amer', 'least', 'half', 'close', 'control', 'city', 'these', 'head', 'start', 'cal', 'dao,', '(see', 'conduct', 'free', 'years,', 'information', 'platform,', 'president,', 'life', 'im', 'country’s', 'air', 'america’s', 'september', 'live', 'much', 'called', 'find', 'policy', 'private', 'us', 'can', 'from', 'killed', 'great', 'like', 'even', 'post', 'recent', 'h', 'na', 'ar', 'which', 'average', 'stated', 'good', 'any', 'mr', 'her', 'mean', 'help', 'came', 'global', 'big', 'ever', 'pro', 'world', 'within', '0', 'ment', 'inter', 'ing', 'since', 'working', 'july', 'third', 'training', 'face', 'first', 'dis', 'only', 'shared', 'programming', 'take', 'theodore', 'mar', 'women', 'com', '2015', 'lyrics', 'airport', 'now', 'en', 'nearly', 'france', 'fares', 'reason', 'a', 'dao', 'year', 'what', 'have', 'ﬁrm', 'campaign', 'and', 'come', 'britain', 'court', 'previous', 'portal', '2', 'pictured)', 'q4', 'having', 'seems', 'research', 'lil', 'you', 'where', 'whether', 'were', '2018', 'digital', 'might', 'will', 'several', 'diﬀerent', 'techniques', 'market', '100', 'karate', 'sxsw', 'according', 'although', 'keep', 'she', 'local', 'risk', 'second', 'rights', 'when', 'baymax', 'known', 'until', 'black', 'health', 'ﬁrst', 'them.', 'offered', 'donald', 'robot', 'firms', 'times', 'won']
with open(filename, 'r') as f:
    for line in f:
        content = re.sub("\"|,>|\./'", "", line.lower())
        datalist.extend(content.split(','))

wordlst = Counter(datalist)
print(wordlst)
lh = len(wordlst)

m200 = wordlst.most_common(lh)

lst = [item[0] for item in m200]
#lst = [i for i in lst if len(i)> 4 and len(i)< 11]
datas = ','.join(lst)

with open('good.txt','a+') as fo:
    fo.write(datas)
